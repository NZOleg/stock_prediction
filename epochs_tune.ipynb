{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olegok\\Anaconda3\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing import sequence\n",
    "import csv \n",
    "import os.path\n",
    "import gc\n",
    "import time\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(seq_len = 20):\n",
    "    data = pd.read_csv('stocks/AAPL.csv')\n",
    "    data = data.drop(['direction_up', 'direction_down','Date', 'direction'], axis=1)\n",
    "    data = data.dropna(axis=0, how='any')\n",
    "    min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    for key in data:\n",
    "        data[key] = min_max_scaler.fit_transform(data[key].values.reshape(-1,1))\n",
    "    x_data = data.as_matrix()\n",
    "    x_data_seq = []\n",
    "    y_data_seq = []\n",
    "    for index in range(len(data) - seq_len): \n",
    "        x_data_seq.append(x_data[index: index + seq_len])\n",
    "        y_data_seq.append(x_data[index + seq_len])\n",
    "    x_train = np.array(x_data_seq[:math.ceil(len(data)*0.8)][:][:])\n",
    "    y_train = np.array(y_data_seq[:math.ceil(len(data)*0.8)][:])\n",
    "    x_test = np.array(x_data_seq[math.ceil(len(data)*0.8):][:][:])\n",
    "    y_test = np.array(y_data_seq[math.ceil(len(data)*0.8):][:])\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(_batch_size, _n_neurons=128 , _dropout=0.5, seq_len=20, _activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(_n_neurons, batch_input_shape=(_batch_size, seq_len, 36)))\n",
    "    model.add(Dropout(_dropout))\n",
    "    #model.add(Flatten())\n",
    "    model.add(Dense(36, activation=_activation)) #relu & signoid\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_dataset(batch_size, x_train, y_train, x_test, y_test): \n",
    "    x_train = x_train[:(x_train.shape[0]//batch_size)*batch_size]\n",
    "    y_train = y_train[:(y_train.shape[0]//batch_size)*batch_size]\n",
    "    x_test = x_test[:(x_test.shape[0]//batch_size)*batch_size]\n",
    "    y_test = y_test[:(y_test.shape[0]//batch_size)*batch_size]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7510 samples, validate on 1850 samples\n",
      "Epoch 1/3\n",
      "7510/7510 [==============================] - 46s 6ms/step - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 2/3\n",
      "7510/7510 [==============================] - 46s 6ms/step - loss: 0.0080 - val_loss: 0.0099\n",
      "Epoch 3/3\n",
      "7510/7510 [==============================] - 48s 6ms/step - loss: 0.0072 - val_loss: 0.0101\n",
      "1850/1850 [==============================] - 3s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_epoch = 3\n",
    "n_neurons = 350\n",
    "batch = 10\n",
    "data = []\n",
    "start_time = time.time()\n",
    "model = Model(batch,n_neurons)\n",
    "x_train, y_train, x_test, y_test = create_dataset()\n",
    "x_train, y_train, x_test, y_test = fit_dataset(batch, x_train, y_train, x_test, y_test)\n",
    "history = model.fit(x_train,\n",
    "     y_train,\n",
    "    batch_size=batch,\n",
    "     epochs=n_epoch,\n",
    "   validation_data=(x_test, y_test),\n",
    "    verbose=1)\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch)\n",
    "data.append(score)\n",
    "data.append(time.time() - start_time)\n",
    "data.append(n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open('epochs_tune.p', 'wb')\n",
    "hist = pd.DataFrame(data=[history.history[\"loss\"], history.history[\"val_loss\"]])\n",
    "pickle.dump(hist, filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_pi2 = open('tryin-3.p', 'rb')\n",
    "# history = pickle.load(file_pi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014049</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>0.007193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009837</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>0.010114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  0.014049  0.008003  0.007193\n",
       "1  0.009837  0.009896  0.010114"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
