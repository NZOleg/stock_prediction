{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olegok\\Anaconda3\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing import sequence\n",
    "import csv \n",
    "import os.path\n",
    "import gc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset(min_max_scaler, seq_len = 20, stock='AAPL', margin = 0):\n",
    "    data = pd.read_csv('stocks/'+stock+'.csv')\n",
    "    data = data.drop(['direction_up', 'direction_down','Date', 'direction'], axis=1)\n",
    "    data = data.dropna(axis=0, how='any')\n",
    "    \n",
    "    for key in data:\n",
    "        data[key] = min_max_scaler.fit_transform(data[key].values.reshape(-1,1))\n",
    "    x_data = data.as_matrix()\n",
    "    x_data_seq = []\n",
    "    y_data_seq = []\n",
    "    for index in range(len(data) - seq_len): \n",
    "        x_data_seq.append(x_data[index: index + seq_len])\n",
    "        y_data_seq.append(x_data[index + seq_len]+margin)\n",
    "    x_train = np.array(x_data_seq[:math.ceil(len(data)*0.8)][:][:])\n",
    "    y_train = np.array(y_data_seq[:math.ceil(len(data)*0.8)][:])\n",
    "    x_test = np.array(x_data_seq[math.ceil(len(data)*0.8):][:][:])\n",
    "    y_test = np.array(y_data_seq[math.ceil(len(data)*0.8):][:])\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(_batch_size, _n_neurons=128 , _dropout=0.5, seq_len=20, _activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(_n_neurons, batch_input_shape=(_batch_size, seq_len, 36)))\n",
    "    model.add(Dropout(_dropout))\n",
    "    #model.add(Flatten())\n",
    "    model.add(Dense(36, activation=_activation)) #relu & signoid\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_dataset(batch_size, x_train, y_train, x_test, y_test): \n",
    "    x_train = x_train[:(x_train.shape[0]//batch_size)*batch_size]\n",
    "    y_train = y_train[:(y_train.shape[0]//batch_size)*batch_size]\n",
    "    x_test = x_test[:(x_test.shape[0]//batch_size)*batch_size]\n",
    "    y_test = y_test[:(y_test.shape[0]//batch_size)*batch_size]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7510 samples, validate on 1860 samples\n",
      "Epoch 1/1\n",
      "7510/7510 [==============================] - 31s 4ms/step - loss: 0.0143 - val_loss: 0.0102\n",
      "1860/1860 [==============================] - 2s 871us/step\n",
      "    index        Date    open    high       low    close      volume  \\\n",
      "90   9379  2018-03-13  182.59  183.50  179.2400  179.970  31168404.0   \n",
      "91   9380  2018-03-14  180.32  180.52  177.8100  178.440  29075469.0   \n",
      "92   9381  2018-03-15  178.50  180.24  178.0701  178.650  22584565.0   \n",
      "93   9382  2018-03-16  178.65  179.12  177.6200  178.020  36836456.0   \n",
      "94   9383  2018-03-19  177.32  177.47  173.6600  175.300  32804695.0   \n",
      "95   9384  2018-03-20  175.24  176.80  174.9400  175.240  19314039.0   \n",
      "96   9385  2018-03-21  175.04  175.09  171.2600  171.270  35247358.0   \n",
      "97   9386  2018-03-22  170.00  172.68  168.6000  168.845  41051076.0   \n",
      "98   9387  2018-03-23  168.39  169.92  164.9400  164.940  40248954.0   \n",
      "99   9388  2018-03-26  168.07  173.10  166.4400  172.770  36272617.0   \n",
      "\n",
      "        macd     macds     macdh     ...      high_delta  low_delta  \\\n",
      "90  2.749622  2.157746  1.183752     ...            1.11    -0.9700   \n",
      "91  2.643510  2.254899  0.777223     ...           -2.98    -1.4300   \n",
      "92  2.547001  2.313319  0.467364     ...           -0.28     0.2601   \n",
      "93  2.392106  2.329077  0.126059     ...           -1.12    -0.4501   \n",
      "94  2.026510  2.268563 -0.484107     ...           -1.65    -3.9600   \n",
      "95  1.712193  2.157289 -0.890192     ...           -0.67     1.2800   \n",
      "96  1.129726  1.951776 -1.644101     ...           -1.71    -3.6800   \n",
      "97  0.467056  1.654832 -2.375553     ...           -2.41    -2.6600   \n",
      "98 -0.368963  1.250073 -3.238072     ...           -2.76    -3.6600   \n",
      "99 -0.395143  0.921030 -2.632346     ...            3.18     1.5000   \n",
      "\n",
      "          pdi        mdi         dx        adx       adxr    change  \\\n",
      "90  36.653211  14.489308  43.337528  27.724935  20.285803 -0.963020   \n",
      "91  32.310918  18.239795  27.835657  27.756570  22.420308 -0.850142   \n",
      "92  28.779470  16.246262  27.835657  27.779166  23.951410  0.117687   \n",
      "93  25.977547  16.506465  22.293286  26.211772  24.597228 -0.352645   \n",
      "94  21.982894  29.791251  15.081576  23.031716  24.149939 -1.527918   \n",
      "95  19.673812  26.661979  15.081576  20.760247  23.181456 -0.034227   \n",
      "96  16.773091  37.668028  38.380801  25.794691  23.928094 -2.265465   \n",
      "97  14.289618  42.704222  49.855571  32.669228  26.425561 -1.415893   \n",
      "98  11.965319  49.867449  61.297806  40.848822  30.546493 -2.312772   \n",
      "99  20.626267  39.393700  31.268649  38.111630  32.707960  4.747181   \n",
      "\n",
      "            vr  prediction  \n",
      "90  118.038821  167.707092  \n",
      "91  127.829160  168.859390  \n",
      "92  117.960646  172.016129  \n",
      "93  121.785410  172.877884  \n",
      "94  126.706820  172.896103  \n",
      "95  105.731918  171.518051  \n",
      "96   84.918961  174.609070  \n",
      "97   71.816450  178.043762  \n",
      "98   59.378506  174.952194  \n",
      "99   56.778087  170.950943  \n",
      "\n",
      "[10 rows x 39 columns]\n",
      "Train on 7510 samples, validate on 1860 samples\n",
      "Epoch 1/1\n",
      "7510/7510 [==============================] - 34s 5ms/step - loss: 0.1366 - val_loss: 0.0223\n",
      "1860/1860 [==============================] - 2s 820us/step\n",
      "    index        Date    open    high       low    close      volume  \\\n",
      "90   9379  2018-03-13  182.59  183.50  179.2400  179.970  31168404.0   \n",
      "91   9380  2018-03-14  180.32  180.52  177.8100  178.440  29075469.0   \n",
      "92   9381  2018-03-15  178.50  180.24  178.0701  178.650  22584565.0   \n",
      "93   9382  2018-03-16  178.65  179.12  177.6200  178.020  36836456.0   \n",
      "94   9383  2018-03-19  177.32  177.47  173.6600  175.300  32804695.0   \n",
      "95   9384  2018-03-20  175.24  176.80  174.9400  175.240  19314039.0   \n",
      "96   9385  2018-03-21  175.04  175.09  171.2600  171.270  35247358.0   \n",
      "97   9386  2018-03-22  170.00  172.68  168.6000  168.845  41051076.0   \n",
      "98   9387  2018-03-23  168.39  169.92  164.9400  164.940  40248954.0   \n",
      "99   9388  2018-03-26  168.07  173.10  166.4400  172.770  36272617.0   \n",
      "\n",
      "        macd     macds     macdh     ...       high_delta  low_delta  \\\n",
      "90  2.749622  2.157746  1.183752     ...             1.11    -0.9700   \n",
      "91  2.643510  2.254899  0.777223     ...            -2.98    -1.4300   \n",
      "92  2.547001  2.313319  0.467364     ...            -0.28     0.2601   \n",
      "93  2.392106  2.329077  0.126059     ...            -1.12    -0.4501   \n",
      "94  2.026510  2.268563 -0.484107     ...            -1.65    -3.9600   \n",
      "95  1.712193  2.157289 -0.890192     ...            -0.67     1.2800   \n",
      "96  1.129726  1.951776 -1.644101     ...            -1.71    -3.6800   \n",
      "97  0.467056  1.654832 -2.375553     ...            -2.41    -2.6600   \n",
      "98 -0.368963  1.250073 -3.238072     ...            -2.76    -3.6600   \n",
      "99 -0.395143  0.921030 -2.632346     ...             3.18     1.5000   \n",
      "\n",
      "          pdi        mdi         dx        adx       adxr    change  \\\n",
      "90  36.653211  14.489308  43.337528  27.724935  20.285803 -0.963020   \n",
      "91  32.310918  18.239795  27.835657  27.756570  22.420308 -0.850142   \n",
      "92  28.779470  16.246262  27.835657  27.779166  23.951410  0.117687   \n",
      "93  25.977547  16.506465  22.293286  26.211772  24.597228 -0.352645   \n",
      "94  21.982894  29.791251  15.081576  23.031716  24.149939 -1.527918   \n",
      "95  19.673812  26.661979  15.081576  20.760247  23.181456 -0.034227   \n",
      "96  16.773091  37.668028  38.380801  25.794691  23.928094 -2.265465   \n",
      "97  14.289618  42.704222  49.855571  32.669228  26.425561 -1.415893   \n",
      "98  11.965319  49.867449  61.297806  40.848822  30.546493 -2.312772   \n",
      "99  20.626267  39.393700  31.268649  38.111630  32.707960  4.747181   \n",
      "\n",
      "            vr   prediction  \n",
      "90  118.038821  1441.533691  \n",
      "91  127.829160  1440.575928  \n",
      "92  117.960646  1442.104736  \n",
      "93  121.785410  1429.670654  \n",
      "94  126.706820  1437.501953  \n",
      "95  105.731918  1428.082520  \n",
      "96   84.918961  1431.017578  \n",
      "97   71.816450  1423.249634  \n",
      "98   59.378506  1428.839111  \n",
      "99   56.778087  1431.231201  \n",
      "\n",
      "[10 rows x 39 columns]\n",
      "Train on 7510 samples, validate on 1860 samples\n",
      "Epoch 1/1\n",
      "6850/7510 [==========================>...] - ETA: 2s - loss: 1.3252"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e8f0448ffb38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m            \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             verbose=1)\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mtest_pred\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epoch=35\n",
    "n_neurons = 350\n",
    "batch = 10\n",
    "seq = 27\n",
    "for stock in ['AAPL','MSFT', 'AMZN', 'TSLA', 'GOOGL']:\n",
    "    for pred_day in [1,3,7]:\n",
    "        min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "        file_name = 'data/'+stock +'-'+ str(pred_day) + '.csv'\n",
    "        model = Model(batch,n_neurons,0.5, seq)\n",
    "        x_train, y_train, x_test, y_test = create_dataset(min_max_scaler,seq,stock, pred_day-1 )\n",
    "        x_train, y_train, x_test, y_test = fit_dataset(batch, x_train, y_train, x_test, y_test)\n",
    "        model.fit(x_train,\n",
    "             y_train,\n",
    "            batch_size=batch,\n",
    "             epochs=n_epoch,\n",
    "           validation_data=(x_test, y_test),\n",
    "            verbose=1)\n",
    "        score = model.evaluate(x_test, y_test, batch_size=batch)\n",
    "        test_pred =  model.predict(x_test[x_test.shape[0]-100:], batch_size=batch)\n",
    "        test_pred = min_max_scaler.inverse_transform(test_pred)\n",
    "        data = pd.read_csv('stocks/'+stock +'.csv')\n",
    "        data = data.drop(['direction_up', 'direction_down', 'direction'], axis=1)\n",
    "        data = data[data.shape[0]-100:].reset_index()\n",
    "        data[\"prediction\"] = pd.Series(test_pred[:,3])\n",
    "        data[\"prediction\"] = data[\"prediction\"].shift(pred_day)\n",
    "        data = data[pred_day:]\n",
    "        data.to_csv('prediction_try/'+stock +'-'+ str(pred_day) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
